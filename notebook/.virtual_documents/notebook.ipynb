import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df= pd.read_csv("../data/water_quality.csv")
df.head()


df.info()


df.columns


df.nunique()


df.isnull().sum()


df.isnull().mean().plot.bar()


df['Potability'].value_counts()


df.hist()
plt.show()


sns.boxplot(data=df,orient='h')
plt.show


sns.heatmap(df.corr(), annot=True, cmap='coolwarm')


df.describe()


sns.pairplot(df, hue="Potability")


skew_value = df.skew().sort_values(ascending=False)
skew_value


new_df=df.copy()
new_df.info()





# fillna value means
for col in df.columns:
    if df[col].isnull().any():
        # mean_value=df[col].mean()
        df[col].fillna(df[col].mean(), inplace=True)


df.isnull().sum()





from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer


numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
numerical_features
# categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()
# categorical_features


# Step 2: Normalize or Standardize Numerical Features
numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean
    ('scaler', MinMaxScaler())  # Normalize using Min-Max scaling
])


# Step 3: Convert Categorical Data into Numerical Format
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # One-hot encode categorical features
])


# Combine transformers into a ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        # ('cat', categorical_transformer, categorical_features)
    ]
)


# Apply the transformations to the dataframe
df_preprocessed = preprocessor.fit_transform(new_df)

# Debug: Check the shape of the transformed data
print(f"Shape of transformed data: {df_preprocessed.shape}")


df_preprocessed





# Convert to DataFrame
all_features=new_df.columns
all_features
df_preprocess = pd.DataFrame(df_preprocessed, columns=all_features)
df_preprocess


df_preprocess.isnull().sum()





x = df.drop('Potability', axis=1)
y = df['Potability']

#test columns
xtest=x.columns
xtest


# StandardScaler
from sklearn.preprocessing import StandardScaler 
scaler = StandardScaler()
x = scaler.fit_transform(x)
x


# test columns feature
dftest = pd.DataFrame(df, columns=xtest)
dftest



# import train-test split 
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)


from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report,  ConfusionMatrixDisplay



mod = []
cv_score=[]
model =[AdaBoostClassifier(), BaggingClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), ExtraTreeClassifier(), KNeighborsClassifier(),XGBClassifier()]
for m in model:
    
    # cv_score.append(cross_val_score(m, X_train, y_train, scoring='accuracy', cv=5).mean())
    mod.append(m)
model_df=pd.DataFrame(columns=['model','cv_score'])
model_df['model']=mod
model_df['cv_score']=cv_score
model_df.sort_values(by=['cv_score'], ascending=True)


param={'n_estimators': [100,200,300,400,500]}
grid_Grd=GridSearchCV(GradientBoostingClassifier(), param_grid=param, cv=5, scoring='accuracy')
grid_Grd.fit(X_train, y_train)
print(f"Best Estimator: {grid_Grd.best_params_} , Best Score : {grid_Grd.best_score_}")


param={'n_estimators': [100,200,300,400,500]}
grid_Bag=GridSearchCV(BaggingClassifier(), param_grid=param, cv=5, scoring='accuracy')
grid_Bag.fit(X_train, y_train)
print(f"Best Estimator: {grid_Bag.best_params_} , Best Score : {grid_Bag.best_score_}")


def get_results(y_test, y_pred):
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    result={'acc:{accuracy}',
            'precision: ',precision,
            'recall: ',recall,
            'f1: ',f1}
    return result


xgb = XGBClassifier(random_state=42)


# Define the parameter grid for XGBoost
param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}
# Perform Grid Search with Cross-Validation
grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)
grid_search.fit(X_train, y_train)

# Get the best estimator
best_xgb = grid_search.best_estimator_

# Predict on the test set
y_pred = best_xgb.predict(X_test)
              

# Print the best parameters and the evaluation metrics
print("Best Parameters:", grid_search.best_params_)

print(get_results (y_test, y_pred))


xgb = XGBClassifier(random_state=42, 
                    colsample_bytree= 1.0,
                    learning_rate= 0.1,
                    max_depth= 7,
                    n_estimators= 200,
                    subsample= 0.8) 
xgb.fit(X_train, y_train)
y_pred = xgb.predict(X_test)
get_results(y_test, y_pred)





from sklearn.metrics import classification_report, confusion_matrix
model1 = GradientBoostingClassifier(n_estimators=500)
model1.fit(X_train,y_train)
pred = model1.predict(X_test)
print(classification_report(y_test, pred))
sns.heatmap(confusion_matrix(y_test, pred), annot=True, fmt='.2f')


from sklearn.metrics import classification_report, confusion_matrix
model2 = BaggingClassifier(n_estimators=80)
model2.fit(X_train,y_train)
pred = model2.predict(X_test)
print(classification_report(y_test, pred))
sns.heatmap(confusion_matrix(y_test, pred), annot=True, fmt='.2f')


x = df.drop('Potability', axis=1)
y = df['Potability']

#test columns
xtest=x.columns
xtest


feature_importance = pd.Series(model1.feature_importances_, index=xtest)
feature_importance.sort_values(ascending=False, inplace=True)
feature_importance.plot(kind='bar')
plt.title(f'{model1}')
plt.show()


#model evaluation
gbc=cross_val_score(model1, X_train, y_train, scoring='accuracy', cv=5).mean()
gbc


bagc=cross_val_score(model2, X_train, y_train, scoring='accuracy', cv=5)
bagc


x = df.drop('Potability', axis=1)
y = df['Potability']

# df.iloc[start:stop:step]
y.iloc[700]


test_df=x.iloc[[700]].values
test_df


ypred=xgb.predict(test_df)[0]
ypred



